import json
import os
from typing import Dict, Any, Optional
import logging

# Configure logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Global variables for connection reuse
_lambda_client = None
_supervisor_agent = None

def get_lambda_client():
    """Lazy initialization of Lambda client with connection reuse."""
    global _lambda_client
    if _lambda_client is None:
        import boto3
        _lambda_client = boto3.client(
            'lambda', 
            region_name='us-east-1',
            config=boto3.session.Config(
                retries={'max_attempts': 2, 'mode': 'adaptive'},
                max_pool_connections=10
            )
        )
    return _lambda_client

def get_supervisor_agent():
    """Lazy initialization of supervisor agent."""
    global _supervisor_agent
    if _supervisor_agent is None:
        from strands import Agent
        from strands.models.bedrock import BedrockModel
        
        # Optimized model configuration
        supervisor_model = BedrockModel(
            region_name="us-east-1",
            model_id="anthropic.claude-3-haiku-20240307-v1:0",
            # Add performance optimizations
            max_tokens=150,  # Limit tokens for routing decisions
            temperature=0.1   # Low temperature for consistent routing
        )
        
        # Shorter, focused system prompt for faster processing
        system_prompt = """Route queries efficiently:
        - COST: cost analysis, spending, forecasts
        - OPTIMIZATION: savings, recommendations, efficiency
        - BOTH: comprehensive analysis
        Respond with only: COST, OPTIMIZATION, or BOTH"""
        
        _supervisor_agent = Agent(
            model=supervisor_model,
            system_prompt=system_prompt
        )
    return _supervisor_agent

class OptimizedFinOpsSupervisor:
    def __init__(self):
        # Downstream agent names
        self.cost_agent = "aws-cost-forecast-agent"
        self.advisor_agent = "trusted-advisor-agent-trusted-advisor-agent"
        
        # Simple keyword-based routing for common patterns
        self.cost_keywords = {'cost', 'spend', 'bill', 'expense', 'forecast', 'april', 'may', 'june', 'month'}
        self.optimization_keywords = {'optimization', 'recommend', 'savings', 'efficiency', 'idle', 'reserved'}
        self.complex_keywords = {'comprehensive', 'complete', 'full', 'both', 'all', 'analysis'}

    def fast_route_query(self, query: str) -> str:
        """Fast keyword-based routing to avoid LLM calls when possible."""
        query_lower = query.lower()
        
        # Check for complex query patterns first
        if any(keyword in query_lower for keyword in self.complex_keywords):
            return "BOTH"
        
        # Count keyword matches
        cost_matches = sum(1 for keyword in self.cost_keywords if keyword in query_lower)
        opt_matches = sum(1 for keyword in self.optimization_keywords if keyword in query_lower)
        
        # If clear winner, route directly
        if cost_matches > opt_matches and opt_matches == 0:
            return "COST"
        elif opt_matches > cost_matches and cost_matches == 0:
            return "OPTIMIZATION"
        elif cost_matches > 0 and opt_matches > 0:
            return "BOTH"
        
        # Fallback to LLM for ambiguous cases
        return None

    def determine_routing(self, query: str) -> str:
        """Determine routing with fast path optimization."""
        # Try fast routing first
        fast_route = self.fast_route_query(query)
        if fast_route:
            logger.info(f"Fast route decision: {fast_route}")
            return fast_route
        
        # Fallback to LLM routing for complex cases
        try:
            logger.info("Using LLM for routing decision")
            supervisor = get_supervisor_agent()
            routing_query = f"Route: {query[:100]}..."  # Truncate for speed
            response = supervisor(routing_query)
            response_text = str(response).upper()
            
            if "BOTH" in response_text:
                return "BOTH"
            elif "OPTIMIZATION" in response_text:
                return "OPTIMIZATION"
            else:
                return "COST"
                
        except Exception as e:
            logger.warning(f"LLM routing failed, using fallback: {str(e)}")
            # Smart fallback based on query content
            return "OPTIMIZATION" if "recommend" in query.lower() else "COST"

    def invoke_lambda_agent(self, function_name: str, query: str) -> Dict[str, Any]:
        """Optimized Lambda invocation with connection reuse."""
        try:
            logger.info(f"Invoking: {function_name}")
            
            lambda_client = get_lambda_client()
            
            response = lambda_client.invoke(
                FunctionName=function_name,
                InvocationType='RequestResponse',
                Payload=json.dumps({"query": query})
            )
            
            if response.get('StatusCode') == 200:
                response_payload = json.loads(response['Payload'].read())
                return {
                    "response": response_payload,
                    "success": True,
                    "agent": function_name
                }
            else:
                return {
                    "error": f"Lambda failed: {response.get('StatusCode')}",
                    "agent": function_name,
                    "success": False
                }
                
        except Exception as e:
            logger.error(f"Lambda invocation error: {str(e)}")
            return {
                "error": str(e),
                "agent": function_name,
                "success": False
            }

    def process_query(self, query: str) -> Dict[str, Any]:
        """Optimized query processing."""
        routing_decision = self.determine_routing(query)
        logger.info(f"Routing: {routing_decision}")
        
        if routing_decision == "BOTH":
            # Parallel processing for complex queries
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
                cost_future = executor.submit(self.invoke_lambda_agent, self.cost_agent, query)
                advisor_future = executor.submit(self.invoke_lambda_agent, self.advisor_agent, query)
                
                cost_results = cost_future.result()
                advisor_results = advisor_future.result()
            
            return {
                "query": query,
                "status": "completed",
                "processing_type": "parallel",
                "cost_analysis": cost_results,
                "optimization_recommendations": advisor_results,
                "routing_method": "fast" if self.fast_route_query(query) else "llm",
                "agent": "AWS-FinOps-Supervisor"
            }
        elif routing_decision == "OPTIMIZATION":
            result = self.invoke_lambda_agent(self.advisor_agent, query)
            result["routing_method"] = "fast" if self.fast_route_query(query) else "llm"
            return result
        else:
            result = self.invoke_lambda_agent(self.cost_agent, query)
            result["routing_method"] = "fast" if self.fast_route_query(query) else "llm"
            return result

def extract_query(event) -> Optional[str]:
    """Optimized query extraction."""
    if isinstance(event, str):
        return event
        
    if isinstance(event, dict):
        # Direct access patterns for speed
        return (event.get("query") or 
                event.get("inputText") or 
                event.get("prompt") or
                (json.loads(event["body"]) if isinstance(event.get("body"), str) else event.get("body", {})).get("query"))
    return None

def format_response(status_code: int, body: dict) -> dict:
    """Optimized response formatting."""
    return {
        "statusCode": status_code,
        "headers": {
            "Content-Type": "application/json",
            "Access-Control-Allow-Origin": "*"
        },
        "body": json.dumps(body)
    }

# Global supervisor instance for reuse
_supervisor = None

def get_supervisor():
    """Get or create supervisor instance."""
    global _supervisor
    if _supervisor is None:
        _supervisor = OptimizedFinOpsSupervisor()
    return _supervisor

def lambda_handler(event, context):
    """Optimized Lambda handler."""
    try:
        query = extract_query(event)
        
        if not query:
            return format_response(400, {
                "error": "No query provided",
                "agent": "AWS-FinOps-Supervisor"
            })

        supervisor = get_supervisor()
        result = supervisor.process_query(query)
        
        return format_response(200, result)
        
    except Exception as e:
        logger.error(f"Handler error: {str(e)}")
        return format_response(500, {
            "error": str(e),
            "agent": "AWS-FinOps-Supervisor"
        })

# Backwards compatibility
handler = lambda_handler
